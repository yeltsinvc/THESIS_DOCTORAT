# filename of the video to process (can be images, eg image%04d.png)
video-filename = ../video/Video_Traffic_RouenSaintSever.mp4
# filename of the database where results are saved
database-filename = data.db
# filename of the homography matrix
homography-filename = homography.txt
# filename of the camera intrinsic matrix
intrinsic-camera-filename = intrinsic-camera.txt
# -0.11759321 0.0148536 0.00030756 -0.00020578 -0.00091816
distortion-coefficients = 1.93439078e-06
distortion-coefficients = 0.00000000e+00
distortion-coefficients = 0.00000000e+00 
distortion-coefficients = 0.00000000e+00 
distortion-coefficients = 0.00000000e+00
# undistorted image multiplication
undistorted-size-multiplication = 1.31
# Interpolation method for remapping image when correcting for distortion: 0 for INTER_NEAREST - a nearest-neighbor interpolation; 1 for INTER_LINEAR - a bilinear interpolation (used by default); 2 for INTER_CUBIC - a bicubic interpolation over 4x4 pixel neighborhood; 3 for INTER_LANCZOS4
interpolation-method = 1
# filename of the mask image (where features are detected)
mask-filename = mask.png
# undistort the video for feature tracking
undistort = false
# load features from database
load-features = false
# display trajectories on the video
display = false
# original video frame rate (number of frames/s)
video-fps = 25.0
# number of digits of precision for all measurements derived from video
# measurement-precision = 3
# first frame to process
frame1 = 0
# number of frame to process: 0 means processing all frames
nframes = 0
# feature tracking
# maximum number of features added at each frame
max-nfeatures = 1000
# quality level of the good features to track 0.0812219538558
feature-quality = 0.0812219538558
# minimum distance between features (px) 3.54964337411
min-feature-distanceklt = 3.54964337411
# size of the block for feature characteristics (px) 7
block-size = 7
# use of Harris corner detector
use-harris-detector = false
# k parameter to detect good features to track (OpenCV)
k = 0.4
# size of the search window at each pyramid level (px) ([1 ?])" 5
window-size = 5
# maximal pyramid level in the feature tracking algorithm [0 maxLevel=5?] 5
pyramid-level = 5
# number of displacement to test minimum feature motion [2 4] 3
ndisplacements = 2
# minimum displacement to keep features (world distance unit or px) ]0. 0.1?] 0.05
min-feature-displacement = 0.001
# maximum feature acceleration (]1 3+])3
acceleration-bound = 3
# maximum feature deviation  0.6 ]0 1])
deviation-bound = 0.9
# number of frames to smooth positions (half window)
smoothing-halfwidth = 5
# number of frames to compute velocities
#nframes-velocity = 5
# maximum number of iterations to stop feature tracking 20
max-number-iterations = 20
# minimum error to reach to stop feature tracking (0.3-0.01) 0.183328975142
min-tracking-error = 0.3
# minimum eigen value of a 2x2 normal matrix of optical flow equations
min-feature-eig-threshold = 1e-4
# minimum length of a feature (number of frames) to consider a feature for grouping
min-feature-time = 15
# Min Max similarity parameters (Beymer et al. method)
# connection distance in feature grouping (world distance unit or px)
mm-connection-distance = 2.68813545522
# segmentation distance in feature grouping (world distance unit or px)
mm-segmentation-distance = 0.81511847456
# maximum distance between features for grouping (world distance unit or px)
max-distance = 5
# minimum cosine of the angle between the velocity vectors for grouping
min-velocity-cosine = 0.8
# minimum average number of features per frame to create a vehicle hypothesis
min-nfeatures-group = 3.16747690802
# name of the configuration file for all classifier information
classifier-filename = classifier.cfg
# Safety analysis
# maximum speed when predicting future motion (km/h)
max-predicted-speed = 50
# time horizon for collision prediction (s)
prediction-time-horizon = 5.0
# collision distance threshold (m)
collision-distance = 1.8
# option to compute crossing zones and predicted PET
crossing-zones = false
# prediction method: cv, cvd, na, ps, mp
prediction-method = na
# number of predicted trajectories (use depends on prediction method)
npredicted-trajectories = 10
# maximum acceleration for normal adaptation input symmetric distribution (m/s2)
max-normal-acceleration = 2
# maximum steering for normal adaptation input symmetric distribution (rad/s)
max-normal-steering = 0.2
# minimum acceleration for input distribution (m/s2) (extreme values used for evasive action distributions)
min-extreme-acceleration = -9.1
# maximum acceleration for input distribution (m/s2) (extreme values used for evasive action distributions)
max-extreme-acceleration = 4.3
# maximum steering for input distribution (rad/s) (extreme values used for evasive action distributions)
max-extreme-steering = 0.5
# use feature positions and velocities for prediction
use-features-prediction = true
# use constant speed (motion pattern based prediction)
constant-speed = false
# point distance threshold, for the chosen metric for trajectory matching using LCSS
max-lcss-distance = 2.
# distance metric for trajectory matching using LCSS
lcss-metric = cityblock
# similarity threshold for trajectory matching on normalized LCSS
min-lcss-similarity = 0.4
# minimum past feature length for past trajectory matching for motion prediction -> using min-feature-time
